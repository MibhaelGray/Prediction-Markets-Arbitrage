{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad2dee8",
   "metadata": {},
   "source": [
    "### PolyMarket API Calls Through Their Gamma API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93b3a3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time: 2025-04-26T15:18:26Z\n",
      "90 days from now: 2025-07-25T15:18:26Z\n",
      "Data returned successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Base URL for Polymarket Gamma API\n",
    "base_url = \"https://gamma-api.polymarket.com/markets\"\n",
    "\n",
    "current_time = datetime.now()\n",
    "ninety_days_from_now = current_time + timedelta(days=90)\n",
    "\n",
    "# Format dates for Polymarket API (using ISO format)\n",
    "current_time_str = current_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "ninety_days_from_now_str = ninety_days_from_now.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# Print the dates we're using to debug\n",
    "print(f\"Current time: {current_time_str}\")\n",
    "print(f\"90 days from now: {ninety_days_from_now_str}\")\n",
    "\n",
    "# Parameters for the markets endpoint\n",
    "params = {\n",
    "    \"limit\": 1000,  # Limit to 10 markets for brevity\n",
    "    \"active\": True,  # Only active markets\n",
    "    \"closed\": False,  # Not closed (still accepting orders)\n",
    "    \"end_date_min\": current_time_str,  # Only markets that haven't closed yet\n",
    "    \"end_date_max\": ninety_days_from_now_str,  # Only markets closing within 90 days\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Make the GET request\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print('Data returned successfully!')\n",
    "        with open('polymarket_markets_901days.json', 'w') as json_file:\n",
    "            json.dump(data, json_file, indent=4, sort_keys=True)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Request failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ca5f12",
   "metadata": {},
   "source": [
    "### Polymarket JSON Data Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8286c225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully extracted to polymarket_markets_data.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extract_polymarket_data(input_filename, output_filename):\n",
    "    try:\n",
    "        with open(input_filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading JSON file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Check if 'markets' key exists in the data\n",
    "    if 'markets' in data:\n",
    "        markets = data['markets']\n",
    "    else:\n",
    "        # If the data is a list of markets directly\n",
    "        markets = data\n",
    "    \n",
    "    # Create CSV file\n",
    "    with open(output_filename, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        # Define CSV headers\n",
    "        fieldnames = ['title', 'description', 'endDate', 'yesPrice', 'noPrice']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        \n",
    "        # Write the header row\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Process each market\n",
    "        for market in markets:\n",
    "            try:\n",
    "                # Extract title (question field)\n",
    "                title = market.get('question', '')\n",
    "                \n",
    "                # Extract description\n",
    "                description = market.get('description', '')\n",
    "                \n",
    "                # Extract end date\n",
    "                end_date = market.get('endDate', '')\n",
    "                \n",
    "                # Extract Yes/No prices\n",
    "                outcome_prices_str = market.get('outcomePrices', '[]')\n",
    "                outcome_prices = json.loads(outcome_prices_str)\n",
    "                \n",
    "                # Default values in case parsing fails\n",
    "                yes_price = 'N/A'\n",
    "                no_price = 'N/A'\n",
    "                \n",
    "                # Get Yes/No prices if available\n",
    "                if len(outcome_prices) >= 2:\n",
    "                    yes_price = outcome_prices[0]\n",
    "                    no_price = outcome_prices[1]\n",
    "                \n",
    "                # Write data to CSV\n",
    "                writer.writerow({\n",
    "                    'title': title,\n",
    "                    'description': description,\n",
    "                    'endDate': end_date,\n",
    "                    'yesPrice': yes_price,\n",
    "                    'noPrice': no_price\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing market: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"Data successfully extracted to {output_filename}\")\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"polymarket_markets_901days.json\"  # Change this to your input file\n",
    "    output_file = \"polymarket_markets_data.csv\"\n",
    "    \n",
    "    extract_polymarket_data(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e9934",
   "metadata": {},
   "source": [
    "### Kalshi API Calls With JSON Output File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ba9d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current time is: 1745699810\n",
      "90 days from now: 1753475810\n",
      "Data returned successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Base URL for Kalshi production API\n",
    "base_url = \"https://api.elections.kalshi.com/trade-api/v2/markets\"\n",
    "\n",
    "current_time = int(time.time())  # Current time in seconds since epoch\n",
    "# The Kalshi API specifically expects timestamps in Unix format (seconds since January 1, 1970)\n",
    "ninety_days_from_now = int((datetime.now() + timedelta(days=90)).timestamp())\n",
    "print(f'The current time is: {current_time}')\n",
    "print(f\"90 days from now: {ninety_days_from_now}\")\n",
    "\n",
    "params = {\n",
    "    \"limit\": 100,\n",
    "    \"status\" : \"open\",\n",
    "    \"min_close_ts\": current_time,\n",
    "    \"max_close_ts\": ninety_days_from_now\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print('Data returned successfully!')\n",
    "        with open('kalshi_markets_closed.json', 'w') as json_file:\n",
    "            json.dump(data, json_file, indent=4, sort_keys=True)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Request failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94c7aba",
   "metadata": {},
   "source": [
    "### Kalshi JSON Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3805b31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully extracted to kalshi_markets_data.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extract_kalshi_data(input_filename, output_filename):\n",
    "    try:\n",
    "        with open(input_filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading JSON file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Check if 'markets' key exists in the data\n",
    "    if 'markets' in data:\n",
    "        markets = data['markets']\n",
    "    else:\n",
    "        # If the data is a list of markets directly\n",
    "        markets = data\n",
    "    \n",
    "    # Create CSV file\n",
    "    with open(output_filename, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        # Define CSV headers\n",
    "        fieldnames = ['title', 'description', 'endDate', 'yesPrice', 'noPrice']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        \n",
    "        # Write the header row\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Process each market\n",
    "        for market in markets:\n",
    "            try:\n",
    "                # Extract title\n",
    "                title = market.get('title', '')\n",
    "                \n",
    "                # Extract description (using rules_primary for description)\n",
    "                description = market.get('rules_primary', '')\n",
    "                \n",
    "                # Extract end date (using expiration_time)\n",
    "                end_date = market.get('expiration_time', '')\n",
    "                \n",
    "                # Extract Yes/No prices\n",
    "                yes_price = market.get('yes_ask', 'N/A')\n",
    "                no_price = market.get('no_ask', 'N/A')\n",
    "                \n",
    "                # Convert price from cents to decimal if it's a number\n",
    "                try:\n",
    "                    if yes_price != 'N/A':\n",
    "                        yes_price = float(yes_price) / 100\n",
    "                    if no_price != 'N/A':\n",
    "                        no_price = float(no_price) / 100\n",
    "                except (ValueError, TypeError):\n",
    "                    # If conversion fails, keep as is\n",
    "                    pass\n",
    "                \n",
    "                # Write data to CSV\n",
    "                writer.writerow({\n",
    "                    'title': title,\n",
    "                    'description': description,\n",
    "                    'endDate': end_date,\n",
    "                    'yesPrice': yes_price,\n",
    "                    'noPrice': no_price\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing market: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"Data successfully extracted to {output_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"kalshi_markets_closed.json\"  \n",
    "    output_file = \"kalshi_markets_data.csv\"\n",
    "    \n",
    "    extract_kalshi_data(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5190988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully joined CSVs and saved to combined_prediction_markets.csv\n",
      "Total records: 200\n",
      "Polymarket records: 100\n",
      "Kalshi records: 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def join_prediction_market_csvs(polymarket_file, kalshi_file, output_file):\n",
    "\n",
    "    poly_df = pd.read_csv(polymarket_file, encoding='utf-8')\n",
    "    kalshi_df = pd.read_csv(kalshi_file, encoding='utf-8')\n",
    "    \n",
    "    poly_df['platform'] = 'Polymarket'\n",
    "    kalshi_df['platform'] = 'Kalshi'\n",
    "    \n",
    "    column_order = ['platform', 'title', 'description', 'endDate', 'yesPrice', 'noPrice']\n",
    "    poly_df = poly_df[column_order]\n",
    "    kalshi_df = kalshi_df[column_order]\n",
    "    \n",
    "    combined_df = pd.concat([poly_df, kalshi_df], ignore_index=True)\n",
    "    combined_df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"Successfully joined CSVs and saved to {output_file}\")\n",
    "    print(f\"Total records: {len(combined_df)}\")\n",
    "    print(f\"Polymarket records: {len(poly_df)}\")\n",
    "    print(f\"Kalshi records: {len(kalshi_df)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    polymarket_file = \"polymarket_markets_data.csv\"\n",
    "    kalshi_file = \"kalshi_markets_data.csv\"\n",
    "    combined_file = \"combined_prediction_markets.csv\"\n",
    "    \n",
    "    join_prediction_market_csvs(polymarket_file, kalshi_file, combined_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b243613",
   "metadata": {},
   "source": [
    "### Prototyping Arbitrage Opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88e74d7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Resolution Date Compatibility**\n",
    "   - Markets should resolve on the same date or within an acceptable timeframe\n",
    "   - Different resolution dates introduce timing risk to your arbitrage\n",
    "\n",
    "2. **Resolution Criteria Alignment**\n",
    "   - Markets should have matching resolution conditions beyond just similar descriptions\n",
    "   - Small differences in resolution criteria can lead to different outcomes\n",
    "\n",
    "3. **Liquidity Assessment**\n",
    "   - Both markets should have sufficient liquidity to execute trades\n",
    "   - Low liquidity could prevent closing positions or cause price slippage\n",
    "\n",
    "4. **Fee Impact Analysis**\n",
    "   - Transaction fees on both platforms should be factored into profit calculations\n",
    "   - Withdrawal and deposit fees can significantly reduce arbitrage profitability\n",
    "\n",
    "5. **Execution Speed Considerations**\n",
    "   - Time between identifying opportunity and executing trades matters\n",
    "   - Prices can shift during execution, especially in volatile markets\n",
    "\n",
    "6. **Platform-Specific Rules**\n",
    "   - Market closure policies should align (some markets can close early)\n",
    "   - Different handling of \"edge cases\" in each platform's rules\n",
    "\n",
    "7. **Capital Lockup Duration**\n",
    "   - Consider how long capital will be tied up in the position\n",
    "   - Shorter resolution timeframes may be preferable for capital efficiency\n",
    "\n",
    "8. **Market Correlation Verification**\n",
    "   - Confirm the markets are truly about the same event\n",
    "   - Watch for subtle differences in wording that change the actual event being predicted\n",
    "\n",
    "For prototyping I will just focus on:\n",
    "\n",
    "1. Contract Name\n",
    "2. Contract Resolution Description\n",
    "3. Spread Of Contracts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
